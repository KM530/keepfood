"""
AIé£Ÿç‰©åˆ†ææœåŠ¡
ä½¿ç”¨Google Gemini APIè¿›è¡Œé£Ÿç‰©åŒ…è£…å›¾ç‰‡åˆ†æ
"""

import os
import json
import logging
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
import google.generativeai as genai
from flask import current_app

logger = logging.getLogger(__name__)


class AIFoodAnalysisService:
    """AIé£Ÿç‰©åˆ†ææœåŠ¡ç±»"""
    
    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY')
        self.model = None
        
        if not self.api_key:
            logger.warning("GOOGLE_API_KEY not found in environment variables")
            return
        
        try:
            # é…ç½®ä»£ç†è®¾ç½®
            self._setup_proxy()
            
            # é…ç½®Gemini API
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash-latest')
            logger.info("AI Analysis Service initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize AI Analysis Service: {e}")
            self.model = None
    
    def _setup_proxy(self):
        """é…ç½®ä»£ç†è®¾ç½®"""
        proxy_host = os.getenv('PROXY_HOST', '127.0.0.1')
        proxy_port = os.getenv('PROXY_PORT', '7890')
        
        if proxy_host and proxy_port:
            proxy_url = f"http://{proxy_host}:{proxy_port}"
            logger.info(f"ğŸŒ é…ç½®ä»£ç†: {proxy_url}")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®©requestsåº“ä½¿ç”¨ä»£ç†
            os.environ['HTTP_PROXY'] = proxy_url
            os.environ['HTTPS_PROXY'] = proxy_url
            
            # ä¹Ÿå¯ä»¥é€šè¿‡requestsçš„Sessionæ¥é…ç½®
            session = requests.Session()
            session.proxies = {
                'http': proxy_url,
                'https': proxy_url
            }
            
            # ä¸ºgoogle-generativeaié…ç½®ä»£ç†
            # è¿™ä¸ªåº“å†…éƒ¨ä½¿ç”¨requestsï¼Œæ‰€ä»¥ç¯å¢ƒå˜é‡è®¾ç½®åº”è¯¥ç”Ÿæ•ˆ
            logger.info(f"âœ… ä»£ç†é…ç½®å®Œæˆ: {proxy_url}")
        else:
            logger.info("ğŸš« æœªé…ç½®ä»£ç†ï¼Œä½¿ç”¨ç›´è¿")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.model is not None and self.api_key is not None
    
    def _ensure_proxy_settings(self):
        """ç¡®ä¿ä»£ç†è®¾ç½®ç”Ÿæ•ˆ"""
        proxy_host = os.getenv('PROXY_HOST', '127.0.0.1')
        proxy_port = os.getenv('PROXY_PORT', '7890')
        
        if proxy_host and proxy_port:
            proxy_url = f"http://{proxy_host}:{proxy_port}"
            
            # é‡æ–°è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä»¥é˜²è¢«è¦†ç›–ï¼‰
            os.environ['HTTP_PROXY'] = proxy_url
            os.environ['HTTPS_PROXY'] = proxy_url
            
            logger.debug(f"ğŸ”„ é‡æ–°ç¡®è®¤ä»£ç†è®¾ç½®: {proxy_url}")
    
    def analyze_food_images(self, image_paths: List[str]) -> Dict[str, Any]:
        """
        åˆ†æé£Ÿç‰©åŒ…è£…å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.is_available():
            raise ValueError("AI Analysis Service is not available")
        
        if not image_paths:
            raise ValueError("No images provided for analysis")
        
        try:
            # ç¡®ä¿ä»£ç†è®¾ç½®åœ¨æ¯æ¬¡è°ƒç”¨æ—¶éƒ½ç”Ÿæ•ˆ
            self._ensure_proxy_settings()
            
            # åŠ è½½å›¾ç‰‡
            images = []
            for path in image_paths:
                if os.path.exists(path):
                    img = Image.open(path)
                    images.append(img)
                    logger.info(f"Loaded image: {path}")
                else:
                    logger.warning(f"Image not found: {path}")
            
            if not images:
                raise ValueError("No valid images found")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_analysis_prompt()
            
            # å‘é€è¯·æ±‚åˆ°Gemini API
            logger.info(f"ğŸš€ é€šè¿‡ä»£ç†å‘é€åˆ†æè¯·æ±‚ï¼Œå¤„ç†{len(images)}å¼ å›¾ç‰‡")
            logger.info(f"ğŸŒ å½“å‰ä»£ç†è®¾ç½®: HTTP_PROXY={os.environ.get('HTTP_PROXY', 'None')}")
            
            content = [prompt] + images
            response = self.model.generate_content(content)
            
            # è§£æå“åº”
            result = self._parse_response(response.text)
            logger.info("âœ… AIåˆ†æå®Œæˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ AIåˆ†æå¤±è´¥: {str(e)}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            raise
    
    def _build_analysis_prompt(self) -> str:
        """æ„å»ºAIåˆ†ææç¤ºè¯"""
        current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        prompt = f"""
è¯·ä»”ç»†åˆ†æè¿™äº›é£Ÿå“åŒ…è£…çš„å›¾ç‰‡ï¼Œç„¶åä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ä¿¡æ¯ã€‚
å½“å‰æ—¥æœŸæ˜¯ï¼š{current_date}ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»å›¾ç‰‡ä¸­è¯†åˆ«å‡ºå®Œæ•´çš„é…æ–™è¡¨å†…å®¹ï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼è¿”å› (ingredients_text)ã€‚
2. ä»é…æ–™è¡¨ä¸­ï¼Œè¯†åˆ«å‡ºå¸¸è§çš„äººå·¥æ·»åŠ å‰‚ã€é«˜ç³–æˆåˆ†ã€é˜²è…å‰‚æˆ–å¸¸è§è¿‡æ•åŸï¼ˆå¦‚éº¸è´¨ã€åšæœç­‰ï¼‰ï¼Œå¹¶åˆ—å‡ºå®ƒä»¬ (harmful_ingredients)ã€‚
3. ä»å›¾ç‰‡ä¸­æ‰¾åˆ°ç”Ÿäº§æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DD (production_date)ã€‚
4. ä»å›¾ç‰‡ä¸­æ‰¾åˆ°ä¿è´¨æœŸä¿¡æ¯ï¼Œæå–æ•°å€¼å’Œå•ä½ï¼Œä¾‹å¦‚"12ä¸ªæœˆ"æå–ä¸ºæ•°å€¼12å’Œå•ä½"month" (shelf_life_value, shelf_life_unit)ã€‚
5. æ ¹æ®ç”Ÿäº§æ—¥æœŸå’Œä¿è´¨æœŸï¼Œè®¡ç®—å‡ºå…·ä½“çš„è¿‡æœŸæ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DD (expiry_date)ã€‚
6. ä»å›¾ç‰‡ä¸­è¯†åˆ«è¥å…»æˆåˆ†è¡¨ï¼Œæå–æ¯100gçš„çƒ­é‡å€¼ï¼Œå•ä½ä¸ºåƒå¡ (calories_kcal)ã€‚
7. æ ¹æ®çƒ­é‡å€¼ï¼Œä¼°ç®—éœ€è¦å¤šå°‘åˆ†é’Ÿçš„è¿åŠ¨æ¥æ¶ˆè€—è¿™äº›çƒ­é‡ï¼ˆå‡è®¾ä¸­ç­‰å¼ºåº¦è¿åŠ¨æ¯åˆ†é’Ÿæ¶ˆè€—5åƒå¡ï¼‰ (energy_offset_info)ã€‚

è¯·å°†æ‰€æœ‰ä¿¡æ¯æ„é€ æˆä¸€ä¸ªJSONå¯¹è±¡ï¼Œç»“æ„å¦‚ä¸‹ï¼š
{{
  "ingredients_text": "å®Œæ•´çš„é…æ–™è¡¨æ–‡å­—å†…å®¹",
  "harmful_ingredients": ["éœ€è¦æ³¨æ„çš„æˆåˆ†1", "éœ€è¦æ³¨æ„çš„æˆåˆ†2"],
  "production_date": "YYYY-MM-DD",
  "shelf_life_value": 12,
  "shelf_life_unit": "month",
  "expiry_date": "YYYY-MM-DD",
  "calories_kcal": 350.5,
  "energy_offset_info": "éœ€è¦çº¦70åˆ†é’Ÿä¸­ç­‰å¼ºåº¦è¿åŠ¨æ¥æ¶ˆè€—"
}}

æ³¨æ„äº‹é¡¹ï¼š
- å¦‚æœæŸä¸ªä¿¡æ¯æ— æ³•ä»å›¾ç‰‡ä¸­è¯†åˆ«å‡ºæ¥ï¼Œè¯·å°†å¯¹åº”å­—æ®µè®¾ä¸ºnull
- ä¿è´¨æœŸå•ä½è¯·ä½¿ç”¨: "day", "month", "year" ä¹‹ä¸€
- æ—¥æœŸæ ¼å¼å¿…é¡»ä¸¥æ ¼æŒ‰ç…§YYYY-MM-DDæ ¼å¼
- çƒ­é‡å€¼è¯·ä¿ç•™ä¸€ä½å°æ•°
- åªè¿”å›JSONå¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜
"""
        return prompt
    
    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº”æ–‡æœ¬"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
            clean_text = response_text.strip()
            if clean_text.startswith('```json'):
                clean_text = clean_text[7:]
            if clean_text.endswith('```'):
                clean_text = clean_text[:-3]
            clean_text = clean_text.strip()
            
            # è§£æJSON
            result = json.loads(clean_text)
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            result = self._validate_and_clean_result(result)
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response as JSON: {e}")
            logger.error(f"Raw response: {response_text}")
            raise ValueError("AI response format is invalid")
    
    def _validate_and_clean_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œæ¸…ç†AIåˆ†æç»“æœ"""
        cleaned = {}
        
        # é…æ–™è¡¨æ–‡å­—
        cleaned['ingredients_text'] = result.get('ingredients_text') or ''
        
        # æœ‰å®³æˆåˆ†åˆ—è¡¨
        harmful = result.get('harmful_ingredients', [])
        cleaned['harmful_ingredients'] = harmful if isinstance(harmful, list) else []
        
        # ç”Ÿäº§æ—¥æœŸéªŒè¯
        prod_date = result.get('production_date')
        if prod_date and self._is_valid_date(prod_date):
            cleaned['production_date'] = prod_date
        else:
            cleaned['production_date'] = None
        
        # ä¿è´¨æœŸæ•°å€¼å’Œå•ä½
        shelf_life_value = result.get('shelf_life_value')
        if isinstance(shelf_life_value, (int, float)) and shelf_life_value > 0:
            cleaned['shelf_life_value'] = int(shelf_life_value)
        else:
            cleaned['shelf_life_value'] = None
        
        shelf_life_unit = result.get('shelf_life_unit')
        if shelf_life_unit in ['day', 'month', 'year']:
            cleaned['shelf_life_unit'] = shelf_life_unit
        else:
            cleaned['shelf_life_unit'] = None
        
        # è¿‡æœŸæ—¥æœŸéªŒè¯
        expiry_date = result.get('expiry_date')
        if expiry_date and self._is_valid_date(expiry_date):
            cleaned['expiry_date'] = expiry_date
        else:
            cleaned['expiry_date'] = None
        
        # çƒ­é‡å€¼
        calories = result.get('calories_kcal')
        if isinstance(calories, (int, float)) and calories > 0:
            cleaned['calories_kcal'] = round(float(calories), 1)
        else:
            cleaned['calories_kcal'] = None
        
        # è¿åŠ¨æ¶ˆè€—ä¿¡æ¯
        cleaned['energy_offset_info'] = result.get('energy_offset_info') or ''
        
        return cleaned
    
    def _is_valid_date(self, date_str: str) -> bool:
        """éªŒè¯æ—¥æœŸæ ¼å¼æ˜¯å¦æ­£ç¡®"""
        try:
            datetime.strptime(date_str, '%Y-%m-%d')
            return True
        except ValueError:
            return False


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
ai_analysis_service = AIFoodAnalysisService()